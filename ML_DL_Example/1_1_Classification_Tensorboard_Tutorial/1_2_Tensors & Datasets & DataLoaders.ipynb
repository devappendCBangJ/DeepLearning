{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35ce4de",
   "metadata": {},
   "source": [
    "# 3. Tensors\n",
    "    1) 특징\n",
    "        - 다차원 배열 다룸\n",
    "        - numpy의 ndarrays와 유사\n",
    "        \n",
    "    2) Tensor Quickstart\n",
    "        1] initilaize\n",
    "            [1] python list -> numpy\n",
    "            [2] numpy -> tensor\n",
    "            [3] another tensor -> tensor\n",
    "                1]] retains the properties of x\n",
    "                2]] overrides the datatype of x\n",
    "            [4] random or constant value tensor\n",
    "        2] Operation\n",
    "            [1] Move device\n",
    "                - device간 data 이동(Runtime -> Change runtime type -> GPU)\n",
    "                - device 위치 : data와 model이 같은 device에 위치해야 학습 가능\n",
    "                - 단점 : load 소모 큼\n",
    "                - 장점 : GPU를 활용한 tensor 연산 시, 연산속도 크게 증가\n",
    "                       (load 소모가 매우 크다는 단점을 극복할 정도의 속도 출력 가능)\n",
    "            [2] Indexing and Slicing\n",
    "            [3] Joining\n",
    "                - .cat : 기존 차원에 tensor를 연속적으로 붙임\n",
    "                - .stack : 새로운 차원에 tensor를 연속적으로 붙임\n",
    "            [4] Arithmetic operaitons\n",
    "            [5] Manipulate tensor shape\n",
    "                - .transpose : 두 차원의 순서 swap\n",
    "                - .permute : 차원의 순서 change\n",
    "                - .reshape : 원소의 순서와 개수를 보존하면서 tensor의 모양 change\n",
    "        3] Bridge with Numpy\n",
    "            [1] tensor -> numpy\n",
    "            [2] numpy -> tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c2dcbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n",
      "NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56760b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]], dtype=torch.int32) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.6866, 0.3475],\n",
      "        [0.3383, 0.1443]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.1853, 0.7534, 0.2875],\n",
      "        [0.6143, 0.1232, 0.8950]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1] initilaize\n",
    "#     [1] python list -> numpy\n",
    "#     [2] numpy -> tensor\n",
    "#     [3] another tensor -> tensor\n",
    "#         1]] retains the properties of x\n",
    "#         2]] overrides the datatype of x\n",
    "#     [4] random or constant value tensor\n",
    "\n",
    "# [1] python list -> numpy\n",
    "py_list = [[1, 2], [3, 4]]\n",
    "x = torch.tensor(py_list)\n",
    "\n",
    "# [2] numpy -> tensor\n",
    "np_array = np.array(py_list)\n",
    "x = torch.from_numpy(np_array)\n",
    "\n",
    "# [3] another tensor -> tensor\n",
    "# 1]] retains the properties of x\n",
    "x_ones = torch.ones_like(x)\n",
    "print(f'Ones Tensor: \\n {x_ones} \\n')\n",
    "\n",
    "# 2]] overrides the datatype of x\n",
    "x_rand = torch.rand_like(x, dtype=torch.float)\n",
    "print(f'Random Tensor: \\n {x_rand} \\n')\n",
    "\n",
    "# [4] random or constant value tensor\n",
    "shape = (2, 3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f'Random Tensor: \\n {rand_tensor} \\n')\n",
    "print(f'Ones Tensor: \\n {ones_tensor} \\n')\n",
    "print(f'Zeros Tensor: \\n {zeros_tensor} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b38c1a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "cuda:0\n",
      "cpu\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "First row: tensor([1., 1., 1., 1.])\n",
      "First column: tensor([1., 1., 1., 1.])\n",
      "Last column: tensor([1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "torch.Size([4, 12])\n",
      "torch.Size([4, 3, 4])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([2, 2])\n",
      "torch.Size([4, 5, 2, 3])\n",
      "torch.Size([3, 4, 5, 2])\n",
      "tensor([[0.6983, 0.5678, 0.8518],\n",
      "        [0.6581, 0.0045, 0.8700]])\n",
      "tensor([[0.6983, 0.5678],\n",
      "        [0.8518, 0.6581],\n",
      "        [0.0045, 0.8700]])\n",
      "tensor([0.6983, 0.5678, 0.8518, 0.6581, 0.0045, 0.8700])\n"
     ]
    }
   ],
   "source": [
    "# 2] Operation\n",
    "#     [1] Move device\n",
    "#         - device간 data 이동(Runtime -> Change runtime type -> GPU)\n",
    "#         - device 위치 : data와 model이 같은 device에 위치해야 학습 가능\n",
    "#         - 단점 : load 소모 큼\n",
    "#         - 장점 : GPU를 활용한 tensor 연산 시, 연산속도 크게 증가\n",
    "#                (load 소모가 매우 크다는 단점을 극복할 정도의 속도 출력 가능)\n",
    "#     [2] Indexing and Slicing\n",
    "#     [3] Joining\n",
    "#         - .cat : 기존 차원에 tensor를 연속적으로 붙임\n",
    "#         - .stack : 새로운 차원에 tensor를 연속적으로 붙임\n",
    "#     [4] Arithmetic operaitons\n",
    "#     [5] Manipulate tensor shape\n",
    "#         - .transpose : 두 차원의 순서 swap\n",
    "#         - .permute : 차원의 순서 change\n",
    "#         - .reshape : 원소의 순서와 개수 보존하면서 tensor의 모양 change\n",
    "\n",
    "# [1] Mode device\n",
    "tensor = torch.rand((3, 4))\n",
    "print(tensor.device)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to('cuda')\n",
    "print(tensor.device)\n",
    "\n",
    "tensor = tensor.to('cpu')\n",
    "print(tensor.device)\n",
    "\n",
    "# [2] Indexing and Slicing\n",
    "tensor = torch.ones((4, 4))\n",
    "print(tensor)\n",
    "print(f'First row: {tensor[0]}') # 첫번재 행\n",
    "print(f'First column: {tensor[:, 0]}') # 첫번재 열\n",
    "print(f'Last column: {tensor[..., -1]}') # 마지막 열\n",
    "\n",
    "tensor[:, 1] = 0\n",
    "print(tensor)\n",
    "\n",
    "# [3] Joining\n",
    "#     - .cat : 지정한 기존 차원에 tensor를 연속적으로 붙임\n",
    "#     - .stack : 지정한 새로운 차원에 tensor를 연속적으로 붙임\n",
    "\n",
    "tensor = torch.ones((4, 4))\n",
    "# .cat\n",
    "t1 = torch.cat([tensor, tensor, tensor], dim = 1)\n",
    "print(t1.shape)\n",
    "\n",
    "# .stack\n",
    "t2 = torch.stack([tensor, tensor, tensor], dim = 1)\n",
    "print(t2.shape)\n",
    "\n",
    "# [4] Arithmetic operaitons\n",
    "x1 = torch.rand((2, 3))\n",
    "x2 = torch.rand((2, 3))\n",
    "x3 = torch.rand((3, 2))\n",
    "\n",
    "y1 = x1 + x2\n",
    "y2 = x1 * x2 # elementwise multiplication\n",
    "y3 = x1 @ x3 # matrix multiplication(A @ B = [N x M] @ [M x K])\n",
    "\n",
    "print(y1.shape)\n",
    "print(y2.shape)\n",
    "print(y3.shape)\n",
    "\n",
    "# [5] Manipulate tensor shape\n",
    "#     - .transpose : 두 차원의 순서 swap\n",
    "#     - .permute : 차원의 순서 change\n",
    "#     - .reshape : 원소의 순서를 보존하면서 tensor의 모양 change\n",
    "\n",
    "x = torch.rand((4, 3, 2, 5))\n",
    "\n",
    "# .transpose\n",
    "y1 = x.transpose(1, 3)\n",
    "print(y1.shape)\n",
    "\n",
    "# .permute\n",
    "y2 = x.permute(1, 0, 3, 2) # 기존에 n번째 차원인 부분을 현재 설정한 위치에 둔다\n",
    "print(y2.shape)\n",
    "\n",
    "# .reshape\n",
    "x = torch.rand((2, 3))\n",
    "\n",
    "y1 = x.reshape((3, 2)) # 기존 원소 개수 = reshape 원소 개수\n",
    "y2 = x.reshape((-1, )) # 1개 행에 전부 표시\n",
    "\n",
    "print(x)\n",
    "print(y1)\n",
    "print(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "815d0ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# 3] Bridge with Numpy\n",
    "#     [1] tensor -> numpy\n",
    "#     [2] numpy -> tensor\n",
    "\n",
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)\n",
    "n2 = t.numpy()\n",
    "\n",
    "print(type(n))\n",
    "print(type(t))\n",
    "print(type(n2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f99dba",
   "metadata": {},
   "source": [
    "# 4. Datasets & DataLoaders(torch.utils.data)\n",
    "    1) Datasets\n",
    "        (1) Bulit In Dataset\n",
    "            1] Load built in dataset\n",
    "                - Pytorch에서 제공하는 유명한 dataset\n",
    "                ex. torchvision.datasets.FashionMNIST\n",
    "                    - root : train/test data 경로\n",
    "                    - train : train/test dataset 지정\n",
    "                    - transform : input에 대한 전처리 과정 지정\n",
    "                    - target_transform : label에 대한 전처리 과정 지정\n",
    "                    - download : data 다운로드\n",
    "                ex. torchvision.datasets.ImageNet\n",
    "                    - root : train/test data 경로\n",
    "                    - split : train/validation dataset 지정\n",
    "                    - transform : input에 대한 전처리 과정 지정\n",
    "                    - target_transform : label에 대한 전처리 과정 지정\n",
    "\n",
    "                    - dataset의 용량이 매우 커서 download 옵션 지원x\n",
    "                ex. 데이터셋 : CIFAR-10\n",
    "                    (1) 데이터셋 특징\n",
    "                        1] 데이터 개수\n",
    "                            - Train : 50,000\n",
    "                            - Test : 10,000\n",
    "                        2] 컬러 : 컬러\n",
    "                        3] 라벨(클래스) 개수 : 10(0 ~ 9)\n",
    "                        4] 이미지 크기 : 32 x 32\n",
    "                        5] 픽셀값 : 0 ~ 255\n",
    "        (2) Custom Dataset\n",
    "            1] Prepare data\n",
    "                - 보편적인 데이터 경로 : root -> train/val -> classes -> images\n",
    "            2] Import packages\n",
    "            3] Custom Dataset\n",
    "                - 보편적인 Dataset : Dataset class 상속\n",
    "                - __init__ : __getitem__ 메소드에서 필요한 변수 정의(객체 생성시 한번만 실행)\n",
    "                - __len__ : 샘플의 개수 반환\n",
    "                - __getitem__ : 인덱스 받아서 single input-label 쌍 반환\n",
    "            4] Test a custom dataset(test code)\n",
    "            \n",
    "            이전 예제 : Cifar10에 모든 데이터 존재\n",
    "            현재 예제 : train, test 폴더에 데이터가 나뉘어져 존재\n",
    "                - Cifar10/train\n",
    "                - Cifar10/test\n",
    "                -> train 파라미터 사용x\n",
    "\n",
    "                -> target_transform은 잘 사용하지 않으므로 파라미터 사용x\n",
    "    2) DataLoader\n",
    "        (1) 기능\n",
    "            - dataset의 input-label을 한 개의 샘플로 생성\n",
    "            - mini batch / reshuffle 수행\n",
    "        (2) 파라미터\n",
    "            - dataset : dataset 지정\n",
    "            - batch_size=1 : batch 당 load할 샘플 개수\n",
    "            - shuffle=None : 샘플 랜덤 추출 설정\n",
    "                train -> shuffle 필요o\n",
    "                test -> shuffle 필요x\n",
    "            - num_workers=0 : data load에 사용할 subprocess 개수 설정(0 : main process에만 load)\n",
    "                batch_size 증가, 전처리 과정 많음 -> worker 수 증가(worker 처리 성능 > worker 생성 종료 및 통신 소요시간)\n",
    "                batch_size 감소, 전처리 과정 적음 -> worker 수 감소(worker 처리 성능 < worker 생성 종료 및 통신 소요시간)\n",
    "                -> worker를 늘리는 것은 상황에 따라 좋을 수도, 안좋을 수도 있다\n",
    "            - drop_last=False : 남은 batch data의 drop 여부 결정\n",
    "                train -> drop_last 무방(shuffle 하기 때문)\n",
    "                test -> drop_last 안됨(모든 데이터 사용으로 정확한 측정을 위해)\n",
    "            \n",
    "                    - root : train/test data 경로\n",
    "                    - train : train/test dataset 지정\n",
    "                    - transform : input에 대한 전처리 과정 지정\n",
    "                    - target_transform : label에 대한 전처리 과정 지정\n",
    "                    - download : data 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7303c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) Bulit In Dataset\n",
    "#     1] Load built in dataset\n",
    "#         - Pytorch에서 제공하는 유명한 dataset\n",
    "#         ex. torchvision.datasets.FashionMNIST\n",
    "#             - root : train/test data 경로\n",
    "#             - train : train/test dataset 지정\n",
    "#             - transform : input에 대한 전처리 과정 지정\n",
    "#             - target_transform : label에 대한 전처리 과정 지정\n",
    "#             - download : data 다운로드\n",
    "#         ex. torchvision.datasets.ImageNet\n",
    "#             - root : train/test data 경로\n",
    "#             - split : train/validation dataset 지정\n",
    "#             - transform : input에 대한 전처리 과정 지정\n",
    "#             - target_transform : label에 대한 전처리 과정 지정\n",
    "#             - dataset의 용량이 매우 커서 download 옵션 지원x\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root = 'data', \n",
    "    train = True, \n",
    "    download = True, \n",
    "    transform = T.ToTensor()\n",
    ")\n",
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root = 'data', \n",
    "    train = False, \n",
    "    download = True, \n",
    "    transform = T.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a46b7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) Custom Dataset\n",
    "#     1] Prepare data\n",
    "#         - 보편적인 데이터 경로 : root -> train/val -> classes -> images\n",
    "#     2] Import packages\n",
    "#     3] Custom Dataset\n",
    "#         - 보편적인 Dataset : Dataset class 상속\n",
    "#         - __init__ : __getitem__ 메소드에서 필요한 변수 정의(객체 생성시 한번만 실행)\n",
    "#         - __len__ : 샘플의 개수 반환\n",
    "#         - __getitem__ : 인덱스 받아서 single input-label 쌍 반환\n",
    "#     4] Test a custom dataset(test code)\n",
    "\n",
    "#     이전 예제 : Cifar10에 모든 데이터 존재\n",
    "#     현재 예제 : train, test 폴더에 데이터가 나뉘어져 존재\n",
    "#         - Cifar10/train\n",
    "#         - Cifar10/test\n",
    "#         -> train 파라미터 사용x\n",
    "\n",
    "#         -> target_transform은 잘 사용하지 않으므로 파라미터 사용x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56a34f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1] Prepare data\n",
    "#     - 보편적인 데이터 경로 : root -> train/val -> classes -> images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c3c78dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2] Import packages\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d9ec9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3] Custom Dataset\n",
    "#     - 보편적인 Dataset : Dataset class 상속\n",
    "#     - __init__ : __getitem__ 메소드에서 필요한 변수 정의(객체 생성시 한번만 실행)\n",
    "#     - __len__ : 샘플의 개수 반환\n",
    "#     - __getitem__ : 인덱스 받아서 single input-label 쌍 반환\n",
    "\n",
    "# 이전 예제 : Cifar10에 모든 데이터 존재\n",
    "# 현재 예제 : train, test 폴더에 데이터가 나뉘어져 존재\n",
    "#     - Cifar10/train\n",
    "#     - Cifar10/test\n",
    "#     -> train 파라미터 사용x\n",
    "\n",
    "#     -> target_transform은 잘 사용하지 않으므로 파라미터 사용x\n",
    "\n",
    "class Cifar10(Dataset):\n",
    "    def __init__(self, root, transform = None):\n",
    "        super(Cifar10, self).__init__()\n",
    "        self.make_dataset(root) # 데이터셋 생성\n",
    "        self.transform = transform # transform 설정\n",
    "        \n",
    "    def make_dataset(self, root):\n",
    "        self.data = []\n",
    "        categories = os.listdir(root) # root 내부 폴더 or 파일 불러오기(여기서는 class명이 폴더명이다!)\n",
    "        categories = sorted(categories)\n",
    "        for label, category in enumerate(categories):\n",
    "            images = glob.glob(f'{root}/{category}/*.png') # 이미지 경로 불러오기\n",
    "            for image in images:\n",
    "                self.data.append((image, label)) # self.data[0] = [image, label]\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.data[idx]\n",
    "        image = self.read_image(image) # 이미지 원본 불러오기\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "    \n",
    "    def read_image(self, path):\n",
    "        image = Image.open(path) # 실제 이미지\n",
    "        return image.convert('RGB') # 흑백 : 1x32x32 / 컬러 : 3x32x32 -> 서로 차원이 조금 다르므로 3x32x32로 통일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d934694f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32]) 0\n"
     ]
    }
   ],
   "source": [
    "# 4] Test a custom dataset(test code)\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.ToTensor(), \n",
    "    T.Normalize((0.5, 0.5, 0.5), (0.25, 0.25, 0.25)) # fashionMNIST : ((0.5, 0.5)) -> 1xHxW / Cifar10 : ((0.5, 0.5, 0.5), (0.25, 0.25, 0.25)) -> 3xHxW\n",
    "])\n",
    "train_root = 'data/Cifar10/train'\n",
    "\n",
    "train_data = Cifar10(train_root, transform)\n",
    "\n",
    "for image, label in train_data:\n",
    "    print(image.shape, label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5432a8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 781\n",
      "10000 10000\n"
     ]
    }
   ],
   "source": [
    "# 2) DataLoader\n",
    "#     (1) 기능\n",
    "#         - dataset의 input-label을 한 개의 샘플로 생성\n",
    "#         - mini batch / reshuffle 수행\n",
    "#     (2) 파라미터\n",
    "#         - dataset : dataset 지정\n",
    "#         - batch_size=1 : batch 당 load할 샘플 개수\n",
    "#         - shuffle=None : 샘플 랜덤 추출 설정\n",
    "#             train -> shuffle 필요o\n",
    "#             test -> shuffle 필요x\n",
    "#         - num_workers=0 : data load에 사용할 subprocess 개수 설정(0 : main process에만 load)\n",
    "#             batch_size 증가, 전처리 과정 많음 -> worker 수 증가(worker 처리 성능 > worker 생성 종료 및 통신 소요시간)\n",
    "#             batch_size 감소, 전처리 과정 적음 -> worker 수 감소(worker 처리 성능 < worker 생성 종료 및 통신 소요시간)\n",
    "#             -> worker를 늘리는 것은 상황에 따라 좋을 수도, 안좋을 수도 있다\n",
    "#         - drop_last=False : 남은 batch data의 drop 여부 결정\n",
    "#             train -> drop_last 무방(shuffle 하기 때문)\n",
    "#             test -> drop_last 안됨(모든 데이터 사용으로 정확한 측정을 위해)\n",
    "\n",
    "#                             - root : train/test data 경로\n",
    "#                 - train : train/test dataset 지정\n",
    "#                 - transform : input에 대한 전처리 과정 지정\n",
    "#                 - target_transform : label에 대한 전처리 과정 지정\n",
    "#                 - download : data 다운로드\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.ToTensor(), \n",
    "    T.Normalize((0.5, 0.5, 0.5), (0.25, 0.25, 0.25))\n",
    "])\n",
    "train_root = 'data/Cifar10/train'\n",
    "train_data = Cifar10(train_root, transform)\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True, drop_last=True)\n",
    "\n",
    "test_root = 'data/Cifar10/test'\n",
    "test_data = Cifar10(test_root, transform)\n",
    "test_loader = DataLoader(test_data, batch_size=1)\n",
    "\n",
    "print(len(train_data), len(train_loader))\n",
    "print(len(test_data), len(test_loader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BangEnv",
   "language": "python",
   "name": "bangenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
