{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 28640\n",
      "    Root location: data/omniglot/meta-train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Grayscale(num_output_channels=1)\n",
      "               RandomCrop(size=(32, 32), padding=4)\n",
      "               ToTensor()\n",
      "           )\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x0000025457AE8E20>\n",
      "[test_dataset] support_example shape :  torch.Size([1, 32, 32])\n",
      "[test_dataset] support_label value :  0\n",
      "[test_loader] support_example shape :  torch.Size([16, 1, 32, 32])\n",
      "[test_loader] support_label shape :  torch.Size([16])\n",
      "[test_loader] support_label value :  tensor([1246, 1243,  970,  538,   76,  608, 1299,  423, 1234,  373,   29,  234,\n",
      "         166,   88,  302,  464])\n",
      "Epoch: 1, Train Accuracy: 0.0012\n",
      "[model_dict] :  odict_keys(['features.layers.0.conv.weight', 'features.layers.0.conv.bias', 'features.layers.0.norm.weight', 'features.layers.0.norm.bias', 'features.layers.0.norm.running_mean', 'features.layers.0.norm.running_var', 'features.layers.0.norm.num_batches_tracked', 'features.layers.1.conv.weight', 'features.layers.1.conv.bias', 'features.layers.1.norm.weight', 'features.layers.1.norm.bias', 'features.layers.1.norm.running_mean', 'features.layers.1.norm.running_var', 'features.layers.1.norm.num_batches_tracked', 'features.layers.2.conv.weight', 'features.layers.2.conv.bias', 'features.layers.2.norm.weight', 'features.layers.2.norm.bias', 'features.layers.2.norm.running_mean', 'features.layers.2.norm.running_var', 'features.layers.2.norm.num_batches_tracked', 'features.layers.3.conv.weight', 'features.layers.3.conv.bias', 'features.layers.3.norm.weight', 'features.layers.3.norm.bias', 'features.layers.3.norm.running_mean', 'features.layers.3.norm.running_var', 'features.layers.3.norm.num_batches_tracked', 'head.weight', 'head.bias'])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'debug_transfer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 79\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[pretrained_dict] : \u001b[39m\u001b[38;5;124m\"\u001b[39m, pretrained_dict\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 79\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [3], line 74\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     72\u001b[0m model_dict \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mstate_dict() \u001b[38;5;66;03m# 현재 신경망 상태 로드\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[model_dict] : \u001b[39m\u001b[38;5;124m\"\u001b[39m, model_dict\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m---> 74\u001b[0m checkpoint_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mcheckpoints\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdebug_transfer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_embedding.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     75\u001b[0m pretrained_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(checkpoint_path)  \u001b[38;5;66;03m# pretrained 상태 로드\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[pretrained_dict] : \u001b[39m\u001b[38;5;124m\"\u001b[39m, pretrained_dict\u001b[38;5;241m.\u001b[39mkeys())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'debug_transfer' is not defined"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import easydict\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics.functional.classification import accuracy\n",
    "\n",
    "from src.engines import pretrain_baseline\n",
    "from src.models import BaselineNet\n",
    "from src.utils import save_checkpoint, save_pretrained_embeddingnet\n",
    "\n",
    "# Jupyter 환경\n",
    "args = easydict.EasyDict({\n",
    "    \"title\" : \"transfer\",\n",
    "    \"device\" : \"cuda\",\n",
    "    \"root\" : \"data/omniglot/meta-train\",\n",
    "    \"num_workers\" : 2,\n",
    "    \"num_classes\" : 1432,\n",
    "    \"batch_size\" : 16,\n",
    "    \"epochs\" : 100,\n",
    "    \"lr\" : 0.001,\n",
    "    \"checkpoints\" : 'checkpoints',\n",
    "    \"pretrain\" : True\n",
    "})\n",
    "\n",
    "def main():\n",
    "    # Build dataset : train만 진행\n",
    "    train_transform = T.Compose([\n",
    "        T.Grayscale(),\n",
    "        T.RandomCrop((32, 32), padding=4),\n",
    "        T.ToTensor(),\n",
    "    ])\n",
    "    train_data = ImageFolder(\"data/omniglot/meta-train\", transform=train_transform)\n",
    "    train_loader = DataLoader(train_data, 16, shuffle=True, num_workers=2, drop_last=True)\n",
    "\n",
    "    print(train_data)\n",
    "    print(train_loader)\n",
    "    for se, sl in train_data:\n",
    "        print(\"[test_dataset] support_example shape : \", se.shape)\n",
    "        print(\"[test_dataset] support_label value : \", sl)\n",
    "        break\n",
    "    for se, sl in train_loader:\n",
    "        print(\"[test_loader] support_example shape : \", se.shape)\n",
    "        print(\"[test_loader] support_label shape : \", sl.shape)\n",
    "        print(\"[test_loader] support_label value : \", sl)\n",
    "        break\n",
    "        \n",
    "    # Build model\n",
    "    model = BaselineNet(args.num_classes, pretrain=args.pretrain)\n",
    "\n",
    "    model = model.to(args.device)\n",
    "\n",
    "    # Build optimizer \n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, args.epochs * len(train_loader))\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    metric_fn = accuracy\n",
    "\n",
    "    # Main loop : train만 진행\n",
    "    for epoch in range(1):\n",
    "        train_summary = pretrain_baseline(train_loader, model, optimizer, scheduler, loss_fn, metric_fn, args.device)\n",
    "        \n",
    "        print(f'Epoch: {epoch + 1}, Train Accuracy: {train_summary[\"metric\"]:.4f}')\n",
    "        save_checkpoint(args.checkpoints, \"debug_transfer\", model, optimizer, epoch + 1)\n",
    "    \n",
    "    save_pretrained_embeddingnet(args.checkpoints, \"debug_transfer\", model.features) # model이 아닌, model.features를 인수로 사용 ♣\n",
    "    \n",
    "    model_dict = model.state_dict() # 현재 신경망 상태 로드\n",
    "    print(\"[model_dict] : \", model_dict.keys())\n",
    "    checkpoint_path = f'{args.checkpoints}/{debug_transfer}_embedding.pth'\n",
    "    pretrained_dict = torch.load(checkpoint_path)  # pretrained 상태 로드\n",
    "    print(\"[pretrained_dict] : \", pretrained_dict.keys())\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "pytorch1.12.1",
   "language": "python",
   "name": "pytorch1.12.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
