{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<src.datasets.OmniglotBaseline object at 0x0000027059B13EB0>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x000002705EDF20A0>\n",
      "<src.datasets.OmniglotBaseline object at 0x000002705EDF2730>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x000002705EE69D60>\n",
      "[train_dataset] support_example shape :  torch.Size([5, 1, 32, 32])\n",
      "[train_dataset] support_label value :  tensor([0, 0, 0, 0, 0])\n",
      "[train_loader] support_example shape :  torch.Size([16, 5, 1, 32, 32])\n",
      "[train_loader] support_label shape :  torch.Size([16, 5])\n",
      "[train_loader] support_label value :  tensor([[22, 22, 22, 22, 22],\n",
      "        [ 2,  2,  2,  2,  2],\n",
      "        [16, 16, 16, 16, 16],\n",
      "        [20, 20, 20, 20, 20],\n",
      "        [19, 19, 19, 19, 19],\n",
      "        [21, 21, 21, 21, 21],\n",
      "        [ 7,  7,  7,  7,  7],\n",
      "        [ 6,  6,  6,  6,  6],\n",
      "        [10, 10, 10, 10, 10],\n",
      "        [ 9,  9,  9,  9,  9],\n",
      "        [ 3,  3,  3,  3,  3],\n",
      "        [12, 12, 12, 12, 12],\n",
      "        [23, 23, 23, 23, 23],\n",
      "        [24, 24, 24, 24, 24],\n",
      "        [17, 17, 17, 17, 17],\n",
      "        [ 8,  8,  8,  8,  8]])\n",
      "[val_dataset] support_example shape :  torch.Size([5, 1, 32, 32])\n",
      "[val_dataset] support_label value :  tensor([0, 0, 0, 0, 0])\n",
      "[val_loader] support_example shape :  torch.Size([16, 5, 1, 32, 32])\n",
      "[val_loader] support_label shape :  torch.Size([16, 5])\n",
      "[val_loader] support_label value :  tensor([[ 0,  0,  0,  0,  0],\n",
      "        [ 1,  1,  1,  1,  1],\n",
      "        [ 2,  2,  2,  2,  2],\n",
      "        [ 3,  3,  3,  3,  3],\n",
      "        [ 4,  4,  4,  4,  4],\n",
      "        [ 5,  5,  5,  5,  5],\n",
      "        [ 6,  6,  6,  6,  6],\n",
      "        [ 7,  7,  7,  7,  7],\n",
      "        [ 8,  8,  8,  8,  8],\n",
      "        [ 9,  9,  9,  9,  9],\n",
      "        [10, 10, 10, 10, 10],\n",
      "        [11, 11, 11, 11, 11],\n",
      "        [12, 12, 12, 12, 12],\n",
      "        [13, 13, 13, 13, 13],\n",
      "        [14, 14, 14, 14, 14],\n",
      "        [15, 15, 15, 15, 15]])\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics.functional.classification import accuracy\n",
    "\n",
    "from src.datasets import OmniglotBaseline\n",
    "from src.models import BaselineNet\n",
    "from src.engines import train_baseline, evaluate_baseline\n",
    "from src.utils import save_checkpoint\n",
    "\n",
    "\n",
    "def main():\n",
    "    accuracies = []\n",
    "\n",
    "    for alphabet, num_classes in zip([\"Atlantean\", \"Japanese_(hiragana)\", \"Japanese_(katakana)\", \"Korean\", \"ULOG\"], [26, 52, 47, 40, 26]):\n",
    "        # Build dataset\n",
    "        root = f'data/omniglot/meta-test/{alphabet}'\n",
    "        train_data = OmniglotBaseline(root, 5, 5, training=True, transform=T.RandomCrop((32, 32), padding=4))\n",
    "        train_loader = DataLoader(train_data, 16, shuffle=True, num_workers=2, drop_last=True) # 입력 : 4차원 텐서 [N = batch_size, channel = 1, height = 32, width = 32]\n",
    "        val_data = OmniglotBaseline(root, 5, 5, training=False)\n",
    "        val_loader = DataLoader(val_data, batch_size=16, num_workers=2)\n",
    "\n",
    "        print(train_data)\n",
    "        print(train_loader)\n",
    "        \n",
    "        print(val_data)\n",
    "        print(val_loader)\n",
    "        for se, sl in train_data:\n",
    "            print(\"[train_dataset] support_example shape : \", se.shape)\n",
    "            print(\"[train_dataset] support_label value : \", sl)\n",
    "            break\n",
    "        for se, sl in train_loader:\n",
    "            print(\"[train_loader] support_example shape : \", se.shape)\n",
    "            print(\"[train_loader] support_label shape : \", sl.shape)\n",
    "            print(\"[train_loader] support_label value : \", sl)\n",
    "            break\n",
    "            \n",
    "        for se, sl in val_data:\n",
    "            print(\"[val_dataset] support_example shape : \", se.shape)\n",
    "            print(\"[val_dataset] support_label value : \", sl)\n",
    "            break\n",
    "        for se, sl in val_loader:\n",
    "            print(\"[val_loader] support_example shape : \", se.shape)\n",
    "            print(\"[val_loader] support_label shape : \", sl.shape)\n",
    "            print(\"[val_loader] support_label value : \", sl)\n",
    "            break\n",
    "        break\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "BangEnv",
   "language": "python",
   "name": "bangenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
