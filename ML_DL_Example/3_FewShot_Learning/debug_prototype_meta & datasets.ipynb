{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 임시 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<src.datasets.OmniglotPrototype object at 0x0000028B51EBF280>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x0000028B51EBF1F0>\n",
      "[test_dataset] support_example shape :  torch.Size([5, 1, 32, 32])\n",
      "[test_dataset] query_example shape :  torch.Size([5, 1, 32, 32])\n",
      "[test_dataset] query_label shape :  torch.Size([5])\n",
      "[test_loader] support_example shape :  torch.Size([20, 5, 1, 32, 32])\n",
      "[test_loader] query_example shape :  torch.Size([20, 5, 1, 32, 32])\n",
      "[test_loader] query_label shape :  torch.Size([20, 5])\n",
      "[test_loader] query_label value :  tensor([[ 739,  739,  739,  739,  739],\n",
      "        [1050, 1050, 1050, 1050, 1050],\n",
      "        [ 627,  627,  627,  627,  627],\n",
      "        [1258, 1258, 1258, 1258, 1258],\n",
      "        [ 446,  446,  446,  446,  446],\n",
      "        [ 987,  987,  987,  987,  987],\n",
      "        [1048, 1048, 1048, 1048, 1048],\n",
      "        [ 138,  138,  138,  138,  138],\n",
      "        [1047, 1047, 1047, 1047, 1047],\n",
      "        [ 318,  318,  318,  318,  318],\n",
      "        [  62,   62,   62,   62,   62],\n",
      "        [ 806,  806,  806,  806,  806],\n",
      "        [ 218,  218,  218,  218,  218],\n",
      "        [ 233,  233,  233,  233,  233],\n",
      "        [  22,   22,   22,   22,   22],\n",
      "        [  74,   74,   74,   74,   74],\n",
      "        [ 799,  799,  799,  799,  799],\n",
      "        [ 367,  367,  367,  367,  367],\n",
      "        [ 981,  981,  981,  981,  981],\n",
      "        [ 620,  620,  620,  620,  620]])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from src.datasets import OmniglotPrototype\n",
    "import torchvision.transforms as T\n",
    "\n",
    "\n",
    "# Build dataset : train만 진행\n",
    "transform = T.RandomCrop((32, 32), padding=4)\n",
    "dataset = OmniglotPrototype(\"data/omniglot/meta-train\", K_s=5, K_q=5, training=True, transform=transform)\n",
    "loader_without_collate_fn = DataLoader(dataset, 20, shuffle=True, num_workers=2, drop_last=True)\n",
    "\n",
    "print(dataset)\n",
    "print(loader_without_collate_fn)\n",
    "def test_dataset(dataset):\n",
    "    for se, qe, ql in dataset:\n",
    "        print(\"[test_dataset] support_example shape : \", se.shape)\n",
    "        print(\"[test_dataset] query_example shape : \", qe.shape)\n",
    "        print(\"[test_dataset] query_label shape : \", ql.shape)\n",
    "        break\n",
    "def test_loader(loader):\n",
    "    for se, qe, ql in loader_without_collate_fn:\n",
    "        print(\"[test_loader] support_example shape : \", se.shape)\n",
    "        print(\"[test_loader] query_example shape : \", qe.shape)\n",
    "        print(\"[test_loader] query_label shape : \", ql.shape)\n",
    "        print(\"[test_loader] query_label value : \", ql)\n",
    "        break\n",
    "\n",
    "test_dataset(dataset)\n",
    "test_loader(loader_without_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test_loader] support_example shape :  torch.Size([20, 5, 1, 32, 32])\n",
      "[test_loader] query_example shape :  torch.Size([20, 5, 1, 32, 32])\n",
      "[test_loader] query_label shape :  torch.Size([20, 5])\n",
      "[test_loader] query_label value :  tensor([[ 887,  887,  887,  887,  887],\n",
      "        [1317, 1317, 1317, 1317, 1317],\n",
      "        [ 936,  936,  936,  936,  936],\n",
      "        [ 204,  204,  204,  204,  204],\n",
      "        [ 298,  298,  298,  298,  298],\n",
      "        [ 219,  219,  219,  219,  219],\n",
      "        [ 429,  429,  429,  429,  429],\n",
      "        [ 455,  455,  455,  455,  455],\n",
      "        [ 372,  372,  372,  372,  372],\n",
      "        [ 341,  341,  341,  341,  341],\n",
      "        [ 981,  981,  981,  981,  981],\n",
      "        [1405, 1405, 1405, 1405, 1405],\n",
      "        [ 328,  328,  328,  328,  328],\n",
      "        [ 545,  545,  545,  545,  545],\n",
      "        [ 423,  423,  423,  423,  423],\n",
      "        [ 114,  114,  114,  114,  114],\n",
      "        [ 614,  614,  614,  614,  614],\n",
      "        [ 206,  206,  206,  206,  206],\n",
      "        [1071, 1071, 1071, 1071, 1071],\n",
      "        [1302, 1302, 1302, 1302, 1302]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def omniglot_prototype_collate_fn(batched_data):\n",
    "    print('[omniglot_prototype_collate_fn] : ', type(batched_data))\n",
    "    print('[omniglot_prototype_collate_fn] : ', len(batched_data))\n",
    "    for data in batched_data:\n",
    "        print('[omniglot_prototype_collate_fn] : ', type(data))\n",
    "        print('[omniglot_prototype_collate_fn] : ', len(data))\n",
    "        break\n",
    "    for a, b, c in batched_data:\n",
    "        print('[omniglot_prototype_collate_fn] : ', a.shape)\n",
    "        print('[omniglot_prototype_collate_fn] : ', b.shape)\n",
    "        print('[omniglot_prototype_collate_fn] : ', c.shape)\n",
    "        \n",
    "        print('[omniglot_prototype_collate_fn] : ', type(a))\n",
    "        print('[omniglot_prototype_collate_fn] : ', type(b))\n",
    "        print('[omniglot_prototype_collate_fn] : ', type(c))\n",
    "        break\n",
    "    \n",
    "    support_images, query_images, query_labels = [], [], []\n",
    "    \n",
    "    count = 0\n",
    "    for a, b, c in batched_data:\n",
    "        support_images.append(a)\n",
    "        query_images.append(b)\n",
    "        query_labels.append([count, count, count])\n",
    "        count = count + 1\n",
    "        break\n",
    "\n",
    "    support_images = torch.stack(support_images, dim=0)\n",
    "    query_images = torch.stack(query_images, dim=0)\n",
    "    query_labels = torch.stack(query_labels, dim=0)\n",
    "    return support_images, query_images, query_labels\n",
    "\n",
    "loader = DataLoader(dataset, 20, shuffle=True, num_workers=2, drop_last=True, collate_fn=omniglot_prototype_collate_fn)\n",
    "test_loader(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<src.datasets.OmniglotPrototype object at 0x000002387123A430>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x000002387121A850>\n",
      "[test_dataset] support_example shape :  torch.Size([5, 1, 32, 32])\n",
      "[test_dataset] query_example shape :  torch.Size([5, 1, 32, 32])\n",
      "[test_dataset] query_label shape :  torch.Size([5])\n",
      "[test_loader] support_example shape :  torch.Size([20, 5, 1, 32, 32])\n",
      "[test_loader] query_example shape :  torch.Size([20, 5, 1, 32, 32])\n",
      "[test_loader] query_label shape :  torch.Size([20, 5])\n",
      "[test_loader] query_label value :  tensor([[ 844,  844,  844,  844,  844],\n",
      "        [1122, 1122, 1122, 1122, 1122],\n",
      "        [1261, 1261, 1261, 1261, 1261],\n",
      "        [1075, 1075, 1075, 1075, 1075],\n",
      "        [1052, 1052, 1052, 1052, 1052],\n",
      "        [ 697,  697,  697,  697,  697],\n",
      "        [1206, 1206, 1206, 1206, 1206],\n",
      "        [ 553,  553,  553,  553,  553],\n",
      "        [ 316,  316,  316,  316,  316],\n",
      "        [ 925,  925,  925,  925,  925],\n",
      "        [ 521,  521,  521,  521,  521],\n",
      "        [ 139,  139,  139,  139,  139],\n",
      "        [1021, 1021, 1021, 1021, 1021],\n",
      "        [1421, 1421, 1421, 1421, 1421],\n",
      "        [ 121,  121,  121,  121,  121],\n",
      "        [ 754,  754,  754,  754,  754],\n",
      "        [ 932,  932,  932,  932,  932],\n",
      "        [ 859,  859,  859,  859,  859],\n",
      "        [ 477,  477,  477,  477,  477],\n",
      "        [ 526,  526,  526,  526,  526]])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from src.datasets import OmniglotPrototype\n",
    "\n",
    "\n",
    "# Build dataset : train만 진행\n",
    "dataset = OmniglotPrototype(\"data/omniglot/meta-train\", K_s=5, K_q=3)\n",
    "loader_without_collate_fn = DataLoader(dataset, batch_size=20, shuffle=True, drop_last=False)\n",
    "\n",
    "print(dataset)\n",
    "print(loader_without_collate_fn)\n",
    "def test_dataset(dataset):\n",
    "    for se, qe, ql in dataset:\n",
    "        print(\"[test_dataset] support_example shape : \", se.shape)\n",
    "        print(\"[test_dataset] query_example shape : \", qe.shape)\n",
    "        print(\"[test_dataset] query_label shape : \", ql.shape)\n",
    "        break\n",
    "def test_loader(loader):\n",
    "    for se, qe, ql in loader_without_collate_fn:\n",
    "        print(\"[test_loader] support_example shape : \", se.shape)\n",
    "        print(\"[test_loader] query_example shape : \", qe.shape)\n",
    "        print(\"[test_loader] query_label shape : \", ql.shape)\n",
    "        print(\"[test_loader] query_label value : \", ql)\n",
    "        break\n",
    "\n",
    "test_dataset(dataset)\n",
    "test_loader(loader_without_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test_loader] support_example shape :  torch.Size([20, 5, 1, 32, 32])\n",
      "[test_loader] query_example shape :  torch.Size([20, 5, 1, 32, 32])\n",
      "[test_loader] query_label shape :  torch.Size([20, 5])\n",
      "[test_loader] query_label value :  tensor([[ 529,  529,  529,  529,  529],\n",
      "        [ 632,  632,  632,  632,  632],\n",
      "        [ 762,  762,  762,  762,  762],\n",
      "        [1170, 1170, 1170, 1170, 1170],\n",
      "        [1082, 1082, 1082, 1082, 1082],\n",
      "        [ 327,  327,  327,  327,  327],\n",
      "        [1026, 1026, 1026, 1026, 1026],\n",
      "        [  60,   60,   60,   60,   60],\n",
      "        [ 120,  120,  120,  120,  120],\n",
      "        [ 824,  824,  824,  824,  824],\n",
      "        [ 511,  511,  511,  511,  511],\n",
      "        [1015, 1015, 1015, 1015, 1015],\n",
      "        [   2,    2,    2,    2,    2],\n",
      "        [1394, 1394, 1394, 1394, 1394],\n",
      "        [  36,   36,   36,   36,   36],\n",
      "        [1039, 1039, 1039, 1039, 1039],\n",
      "        [1229, 1229, 1229, 1229, 1229],\n",
      "        [ 195,  195,  195,  195,  195],\n",
      "        [ 422,  422,  422,  422,  422],\n",
      "        [1328, 1328, 1328, 1328, 1328]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def omniglot_prototype_collate_fn(batched_data):\n",
    "    support_images, query_images, query_labels = [], [], []\n",
    "    \n",
    "    print('[omniglot_prototype_collate_fn] : ', type(batched_data))\n",
    "    \n",
    "    return support_images, query_images, query_labels\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=20, shuffle=True, collate_fn=omniglot_prototype_collate_fn, pin_memory=True)\n",
    "test_loader(loader)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "BangEnv",
   "language": "python",
   "name": "bangenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
