{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce29948f",
   "metadata": {},
   "source": [
    "Pytorch 공부 사이트 : https://wikidocs.net/52460  \n",
    "\n",
    " 1. 목차  \n",
    "    1) 다중변수 선형회귀(Multivariate Linear Regression) 복습  \n",
    "    2) \"minibatch\" Gradient Descent 이론  \n",
    "    3) PyTorch Dataset and DataLoader : 데이터 정의(Data definition) 간단히  \n",
    " 2. \"minibatch\" Gradient Descent : 엄청난 양의 데이터 다룸  \n",
    "    0) 특징\n",
    "        - 목적 : 복잡한 모델 문제 해결을 위함  \n",
    "            기존 gradient descent :  \n",
    "                엄청난 양의 데이터 필요  \n",
    "                느린 속도  \n",
    "                하드웨어적 한계  \n",
    "            minibatch gradient descent : 일부분의 데이터만 학습하자!  \n",
    "<img src=\"./Minibatch_Gradient_Descent.png\" width=\"300\" height=\"300\">  \n",
    "<img src=\"./Minibatch_Gradient_Descent2.png\" width=\"400\" height=\"400\">  \n",
    "        - 장점 : 업데이트 빠름  \n",
    "        - 단점 : 잘못된 방향 업데이트 가능성  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a181b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20, Batch : 1/3, Cost : 19461.726562\n",
      "Epoch    0/20, Batch : 2/3, Cost : 3543.492920\n",
      "Epoch    0/20, Batch : 3/3, Cost : 924.778503\n",
      "Epoch    1/20, Batch : 1/3, Cost : 415.731049\n",
      "Epoch    1/20, Batch : 2/3, Cost : 309.799774\n",
      "Epoch    1/20, Batch : 3/3, Cost : 76.175262\n",
      "Epoch    2/20, Batch : 1/3, Cost : 9.754256\n",
      "Epoch    2/20, Batch : 2/3, Cost : 17.440784\n",
      "Epoch    2/20, Batch : 3/3, Cost : 2.478501\n",
      "Epoch    3/20, Batch : 1/3, Cost : 5.674511\n",
      "Epoch    3/20, Batch : 2/3, Cost : 3.290919\n",
      "Epoch    3/20, Batch : 3/3, Cost : 1.989660\n",
      "Epoch    4/20, Batch : 1/3, Cost : 4.857816\n",
      "Epoch    4/20, Batch : 2/3, Cost : 2.860577\n",
      "Epoch    4/20, Batch : 3/3, Cost : 2.369841\n",
      "Epoch    5/20, Batch : 1/3, Cost : 7.257009\n",
      "Epoch    5/20, Batch : 2/3, Cost : 4.822524\n",
      "Epoch    5/20, Batch : 3/3, Cost : 0.000306\n",
      "Epoch    6/20, Batch : 1/3, Cost : 4.370424\n",
      "Epoch    6/20, Batch : 2/3, Cost : 0.652697\n",
      "Epoch    6/20, Batch : 3/3, Cost : 7.350837\n",
      "Epoch    7/20, Batch : 1/3, Cost : 2.190479\n",
      "Epoch    7/20, Batch : 2/3, Cost : 5.803584\n",
      "Epoch    7/20, Batch : 3/3, Cost : 4.338858\n",
      "Epoch    8/20, Batch : 1/3, Cost : 3.889690\n",
      "Epoch    8/20, Batch : 2/3, Cost : 1.343830\n",
      "Epoch    8/20, Batch : 3/3, Cost : 7.955540\n",
      "Epoch    9/20, Batch : 1/3, Cost : 2.920218\n",
      "Epoch    9/20, Batch : 2/3, Cost : 4.226041\n",
      "Epoch    9/20, Batch : 3/3, Cost : 4.793571\n",
      "Epoch   10/20, Batch : 1/3, Cost : 1.796885\n",
      "Epoch   10/20, Batch : 2/3, Cost : 3.680162\n",
      "Epoch   10/20, Batch : 3/3, Cost : 5.862227\n",
      "Epoch   11/20, Batch : 1/3, Cost : 3.566226\n",
      "Epoch   11/20, Batch : 2/3, Cost : 1.600133\n",
      "Epoch   11/20, Batch : 3/3, Cost : 7.422582\n",
      "Epoch   12/20, Batch : 1/3, Cost : 4.491193\n",
      "Epoch   12/20, Batch : 2/3, Cost : 1.770456\n",
      "Epoch   12/20, Batch : 3/3, Cost : 4.126101\n",
      "Epoch   13/20, Batch : 1/3, Cost : 5.998109\n",
      "Epoch   13/20, Batch : 2/3, Cost : 3.925344\n",
      "Epoch   13/20, Batch : 3/3, Cost : 1.602618\n",
      "Epoch   14/20, Batch : 1/3, Cost : 4.907825\n",
      "Epoch   14/20, Batch : 2/3, Cost : 2.879524\n",
      "Epoch   14/20, Batch : 3/3, Cost : 2.276675\n",
      "Epoch   15/20, Batch : 1/3, Cost : 4.447844\n",
      "Epoch   15/20, Batch : 2/3, Cost : 0.487418\n",
      "Epoch   15/20, Batch : 3/3, Cost : 7.622540\n",
      "Epoch   16/20, Batch : 1/3, Cost : 4.095036\n",
      "Epoch   16/20, Batch : 2/3, Cost : 3.381731\n",
      "Epoch   16/20, Batch : 3/3, Cost : 0.786595\n",
      "Epoch   17/20, Batch : 1/3, Cost : 3.233294\n",
      "Epoch   17/20, Batch : 2/3, Cost : 2.236240\n",
      "Epoch   17/20, Batch : 3/3, Cost : 6.218987\n",
      "Epoch   18/20, Batch : 1/3, Cost : 3.213155\n",
      "Epoch   18/20, Batch : 2/3, Cost : 3.403655\n",
      "Epoch   18/20, Batch : 3/3, Cost : 4.741131\n",
      "Epoch   19/20, Batch : 1/3, Cost : 4.713345\n",
      "Epoch   19/20, Batch : 2/3, Cost : 1.699881\n",
      "Epoch   19/20, Batch : 3/3, Cost : 4.440262\n",
      "Epoch   20/20, Batch : 1/3, Cost : 4.241045\n",
      "Epoch   20/20, Batch : 2/3, Cost : 2.479024\n",
      "Epoch   20/20, Batch : 3/3, Cost : 2.710559\n"
     ]
    }
   ],
   "source": [
    "# 전체 코드\n",
    "\n",
    "# 모듈 불러오기\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 데이터셋 상속\n",
    "class CustomDataset(Dataset):\n",
    "    # 데이터셋 정의 : __init__(self)\n",
    "    def __init__(self):\n",
    "        self.x_data = [[73, 80, 75], [93, 88, 93], [89, 91, 90], [96, 98, 100], [73, 66, 70]]\n",
    "        self.y_data = [[152], [185], [180], [196], [142]]\n",
    "\n",
    "    # 데이터셋 원소 개수 : __len__(self)\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    # 인덱스에 상응하는 데이터셋 데이터 : __getitem__(self, idx)\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.FloatTensor(self.x_data[idx])\n",
    "        y = torch.FloatTensor(self.y_data[idx])\n",
    "        return x, y\n",
    "\n",
    "# 데이터셋 정의\n",
    "dataset = CustomDataset()\n",
    "\n",
    "# 데이터셋 설정\n",
    "dataloader = DataLoader(dataset, batch_size = 2, shuffle = True)\n",
    "    # 사용할 데이터셋\n",
    "    # batch_size : minibatch의 크기\n",
    "        # 보통 2의 제곱수 사용 ex. 16, 32, 64, 128, 256, 512, ...\n",
    "    # shuffle : Epoch마다 데이터셋 섞어줌\n",
    "    \n",
    "# 모델 초기화\n",
    "# W = torch.zeros((3, 1), requires_grad=True)\n",
    "# b = torch.zeros(1, requires_grad=True)\n",
    "class MultivariateLinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(3, 1) # 다중 선형 회귀이므로 input_dim=3, output_dim=1.\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "model = MultivariateLinearRegressionModel()\n",
    "    # model = nn.Linear(3,1)\n",
    "    \n",
    "# Optimzer 설정\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)\n",
    "\n",
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    for batch_idx, samples in enumerate(dataloader): # ♣\n",
    "        x_train, y_train = samples\n",
    "        # H(x) 계산\n",
    "        # hypothesis = x_train.matmul(W) + b\n",
    "        prediction = model(x_train)\n",
    "        \n",
    "        # cost 계산\n",
    "        # cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "        cost = F.mse_loss(prediction, y_train)\n",
    "        \n",
    "        # cost로 H(x) 개선\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print('Epoch {:4d}/{}, Batch : {}/{}, Cost : {:.6f}'.format(epoch, nb_epochs, batch_idx + 1, \n",
    "            len(dataloader), cost.item()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
