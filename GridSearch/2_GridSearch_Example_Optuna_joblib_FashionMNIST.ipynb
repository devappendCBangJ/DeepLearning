{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61e87e32",
   "metadata": {},
   "source": [
    "## 1. 일반 FashionMNIST 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f0f7a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 불러오기\n",
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ee22af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader 함수 정의\n",
    "def get_mnist_loaders(train_batch_size, test_batch_size):\n",
    "    \"\"\"Get MNIST data loaders\"\"\"\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('./data', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=train_batch_size, shuffle=True)\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('./data', train=False, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=test_batch_size, shuffle=True)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d945e287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, activation):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.activation = activation \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.conv1(x))\n",
    "        x = self.conv2(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f988dedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test 정의\n",
    "def train(log_interval, model, train_loader, optimizer, epoch, device):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.to(device))\n",
    "        loss = F.nll_loss(output, target.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))           \n",
    "\n",
    "def test(model, test_loader, device):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data.to(device))\n",
    "            test_loss += F.nll_loss(output, target.to(device), reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.to(device).view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3e9712a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.298800\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.216094\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.097683\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 2.019460\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 1.774781\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 1.463632\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 1.138829\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 1.096267\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 1.095197\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.576627\n"
     ]
    }
   ],
   "source": [
    "# 전체 시스템 정의\n",
    "def train_mnist():\n",
    "    cfg = { 'device' : \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "          'train_batch_size' : 64,\n",
    "          'test_batch_size' : 1000,\n",
    "          'n_epochs' : 1,\n",
    "          'seed' : 0,\n",
    "          'log_interval' : 100,\n",
    "          'save_model' : False,\n",
    "          'lr' : 0.001,\n",
    "          'momentum': 0.5,\n",
    "          'optimizer': optim.SGD,\n",
    "          'activation': F.relu\n",
    "          }\n",
    "\n",
    "    torch.manual_seed(cfg['seed'])\n",
    "    train_loader, test_loader = get_mnist_loaders(cfg['train_batch_size'], cfg['test_batch_size'])\n",
    "    model = Net(cfg['activation']).to(cfg['device'])\n",
    "    optimizer = cfg['optimizer'](model.parameters(), lr=cfg['lr'])\n",
    "    for epoch in range(1, cfg['n_epochs'] + 1):\n",
    "        train(cfg['log_interval'], model, train_loader, optimizer, epoch, cfg['device'])\n",
    "        test_accuracy = test(model, test_loader, cfg['device'])\n",
    "\n",
    "    if cfg['save_model']:\n",
    "        torch.save(model.state_dict(), \"C:\\\\Users\\\\Bang\\\\JupyterProjects\\\\Pytorch_GridSearch_Example\\\\model\\\\mnist_cnn.pt\")\n",
    "\n",
    "    return test_accuracy\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e593a97",
   "metadata": {},
   "source": [
    "## 2. GridSearch 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21e1361f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in c:\\users\\bang\\anaconda\\lib\\site-packages (3.0.3)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\bang\\anaconda\\lib\\site-packages (from optuna) (1.8.1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\bang\\anaconda\\lib\\site-packages (from optuna) (5.4.1)\n",
      "Requirement already satisfied: importlib-metadata<5.0.0 in c:\\users\\bang\\anaconda\\lib\\site-packages (from optuna) (4.12.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\bang\\anaconda\\lib\\site-packages (from optuna) (1.21.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\bang\\anaconda\\lib\\site-packages (from optuna) (4.59.0)\n",
      "Requirement already satisfied: cmaes>=0.8.2 in c:\\users\\bang\\anaconda\\lib\\site-packages (from optuna) (0.9.0)\n",
      "Requirement already satisfied: scipy<1.9.0,>=1.7.0 in c:\\users\\bang\\anaconda\\lib\\site-packages (from optuna) (1.8.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in c:\\users\\bang\\anaconda\\lib\\site-packages (from optuna) (1.4.7)\n",
      "Requirement already satisfied: cliff in c:\\users\\bang\\anaconda\\lib\\site-packages (from optuna) (4.1.0)\n",
      "Requirement already satisfied: colorlog in c:\\users\\bang\\anaconda\\lib\\site-packages (from optuna) (6.7.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\bang\\anaconda\\lib\\site-packages (from optuna) (20.9)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\bang\\anaconda\\lib\\site-packages (from alembic>=1.5.0->optuna) (5.10.0)\n",
      "Requirement already satisfied: Mako in c:\\users\\bang\\anaconda\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.2.4)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\bang\\anaconda\\lib\\site-packages (from importlib-metadata<5.0.0->optuna) (3.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\bang\\anaconda\\lib\\site-packages (from packaging>=20.0->optuna) (2.4.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\bang\\anaconda\\lib\\site-packages (from sqlalchemy>=1.3.0->optuna) (1.0.0)\n",
      "Requirement already satisfied: cmd2>=1.0.0 in c:\\users\\bang\\anaconda\\lib\\site-packages (from cliff->optuna) (2.4.2)\n",
      "Requirement already satisfied: stevedore>=2.0.1 in c:\\users\\bang\\anaconda\\lib\\site-packages (from cliff->optuna) (4.1.1)\n",
      "Requirement already satisfied: autopage>=0.4.0 in c:\\users\\bang\\anaconda\\lib\\site-packages (from cliff->optuna) (0.5.1)\n",
      "Requirement already satisfied: PrettyTable>=0.7.2 in c:\\users\\bang\\anaconda\\lib\\site-packages (from cliff->optuna) (3.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\bang\\anaconda\\lib\\site-packages (from colorlog->optuna) (0.4.4)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in c:\\users\\bang\\anaconda\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
      "Requirement already satisfied: pyperclip>=1.6 in c:\\users\\bang\\anaconda\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n",
      "Requirement already satisfied: attrs>=16.3.0 in c:\\users\\bang\\anaconda\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (20.3.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\bang\\anaconda\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (3.4.1)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in c:\\users\\bang\\anaconda\\lib\\site-packages (from stevedore>=2.0.1->cliff->optuna) (5.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\bang\\anaconda\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "# 패키지 설치\n",
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed903047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 불러오기(GridSearch)\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b887294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 시스템 정의\n",
    "def train_mnist(trial):\n",
    "    cfg = { 'device' : \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        'train_batch_size' : 64,\n",
    "        'test_batch_size' : 1000,\n",
    "        'n_epochs' : trial.suggest_int('n_epochs', 3, 5, 1),\n",
    "        'seed' : 0,\n",
    "        'log_interval' : 100,\n",
    "        'save_model' : False,\n",
    "        'lr' : trial.suggest_loguniform('lr', 1e-3, 1e-2),  \n",
    "        'momentum' : trial.suggest_uniform('momentum', 0.4, 0.99),\n",
    "        'optimizer': trial.suggest_categorical('optimizer',[optim.SGD, optim.RMSprop]),\n",
    "        'activation': F.relu\n",
    "        }\n",
    "\n",
    "    torch.manual_seed(cfg['seed'])\n",
    "    train_loader, test_loader = get_mnist_loaders(cfg['train_batch_size'], cfg['test_batch_size'])\n",
    "    model = Net(cfg['activation']).to(cfg['device'])\n",
    "    optimizer = cfg['optimizer'](model.parameters(), lr=cfg['lr'])\n",
    "    for epoch in range(1, cfg['n_epochs'] + 1):\n",
    "        train(cfg['log_interval'], model, train_loader, optimizer, epoch, cfg['device'])\n",
    "        test_accuracy = test(model, test_loader, cfg['device'])\n",
    "\n",
    "    if cfg['save_model']:\n",
    "        torch.save(model.state_dict(), \"C:\\\\Users\\\\Bang\\\\JupyterProjects\\\\Pytorch_GridSearch_Example\\\\model\\\\mnist_cnn.pt\")\n",
    "\n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0fab823",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-28 14:53:47,437]\u001b[0m A new study created in memory with name: no-name-0f1f6355-b1fe-4099-b71d-c15d824902f6\u001b[0m\n",
      "C:\\Users\\Bang\\AppData\\Local\\Temp\\ipykernel_19752\\2320783044.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lr' : trial.suggest_loguniform('lr', 1e-3, 1e-2),\n",
      "C:\\Users\\Bang\\AppData\\Local\\Temp\\ipykernel_19752\\2320783044.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'momentum' : trial.suggest_uniform('momentum', 0.4, 0.99),\n",
      "C:\\Users\\Bang\\Anaconda\\envs\\BangEnv\\lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.sgd.SGD'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\Bang\\Anaconda\\envs\\BangEnv\\lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.rmsprop.RMSprop'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.298800\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.153982\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.933691\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 1.704710\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 1.305684\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.889822\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.659555\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.765362\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.857396\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.381847\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.472006\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.705421\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.406385\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.414987\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.454198\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.445403\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.486965\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.292097\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.355914\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.397281\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.264052\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.298238\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.470658\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.424595\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.324227\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.271331\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.343761\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.726469\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.350015\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.440633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2022-11-28 14:54:21,934]\u001b[0m Trial 0 failed because of the following error: The value None could not be cast to float.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.298800\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.916815\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.738410\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.773309\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.665731\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.338953\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.211691\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.436145\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.459279\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.185565\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.234768\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.482173\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.165351\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.241864\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.274767\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.288420\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.251635\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.161490\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.217981\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.231815\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.199566\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.169758\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.337799\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.286807\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.266715\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.098781\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.248108\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.552600\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.276871\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.331812\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.204201\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.116034\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.373000\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.111791\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.390930\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.187634\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.213452\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.145079\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.250849\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.100553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2022-11-28 14:55:08,315]\u001b[0m Trial 1 failed because of the following error: The value None could not be cast to float.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.298800\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 1.836667\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.704407\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 1.454037\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 1.104340\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.890457\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.812572\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.775965\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.527517\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.381113\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.471885\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.693377\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.273016\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 1.340359\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.347138\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.482067\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.457607\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.397819\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.361457\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.722266\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.668970\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.406023\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.407584\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.426029\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.302046\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.289070\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.623531\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 1.093651\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.444698\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.369419\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.781151\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.352335\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 1.027992\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.291421\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 1.287529\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.879254\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.712286\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.349864\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.501839\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.607460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2022-11-28 14:55:54,551]\u001b[0m Trial 2 failed because of the following error: The value None could not be cast to float.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.298800\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.822247\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.635373\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.683305\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.444544\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.231782\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.271380\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.745299\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.179065\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.239266\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.234127\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.421748\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.116661\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.229756\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.190156\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.173884\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.083465\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.049521\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.130986\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.196971\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.140817\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.115725\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.116544\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.179137\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.178854\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.014879\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.101380\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.497623\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.158939\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.258187\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.240971\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.014684\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.196677\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.062479\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.139166\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.094766\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.085592\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.224468\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.443125\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.123005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2022-11-28 14:56:40,865]\u001b[0m Trial 3 failed because of the following error: The value None could not be cast to float.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.298800\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 1.664164\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.061702\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.993751\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.787368\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.423050\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.299174\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.484947\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.550201\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.225208\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.262270\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.555984\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.215195\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.272887\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.322814\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.319662\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.312370\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.191914\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.272106\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.285112\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.192634\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.200306\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.397485\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.313021\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.307880\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.141751\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.294477\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.619418\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.280353\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.362844\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.288089\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.169533\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.506750\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.155326\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.451933\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.252772\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.262401\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.172007\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.311305\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.154787\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.238872\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.229084\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.192011\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.121545\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.196184\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.112025\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.120859\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.182760\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.216512\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.203501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2022-11-28 14:57:38,719]\u001b[0m Trial 4 failed because of the following error: The value None could not be cast to float.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# GridSearch 정의\n",
    "study = optuna.create_study(sampler=optuna.samplers.TPESampler(), direction='maximize')\n",
    "\n",
    "# GridSearch 학습\n",
    "study.optimize(train_mnist, n_trials=5) # study.optimize(train_mnist, n_trials=20, direction='maximize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78f890fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Bang\\\\JupyterProjects\\\\Pytorch_GridSearch_Example\\\\GridSearch\\\\mnist_optuna.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 라이브러리 불러오기(joblib)\n",
    "import joblib\n",
    "\n",
    "# GridSearch 학습 저장\n",
    "joblib.dump(study, 'C:\\\\Users\\\\Bang\\\\JupyterProjects\\\\Pytorch_GridSearch_Example\\\\GridSearch\\\\mnist_optuna.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b35ff745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>params_lr</th>\n",
       "      <th>params_momentum</th>\n",
       "      <th>params_n_epochs</th>\n",
       "      <th>params_optimizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001541</td>\n",
       "      <td>0.487012</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0.007495</td>\n",
       "      <td>0.881453</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>0.008898</td>\n",
       "      <td>0.930849</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number value  params_lr  params_momentum  params_n_epochs  \\\n",
       "0       0  None   0.001541         0.487012                3   \n",
       "1       1  None   0.007495         0.881453                4   \n",
       "2       2  None   0.008898         0.930849                4   \n",
       "\n",
       "                        params_optimizer  \n",
       "0          <class 'torch.optim.sgd.SGD'>  \n",
       "1          <class 'torch.optim.sgd.SGD'>  \n",
       "2  <class 'torch.optim.rmsprop.RMSprop'>  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study = joblib.load('C:\\\\Users\\\\Bang\\\\JupyterProjects\\\\Pytorch_GridSearch_Example\\\\GridSearch\\\\mnist_optuna.pkl')\n",
    "df = study.trials_dataframe().drop(['duration', 'state','datetime_start','datetime_complete'], axis=1)\n",
    "# 최적의 파라미터를 확인하기 위해서 study.best_trial및 study.best_params도 사용할 수 있다.\n",
    "# 예를 들어 파라미터 간의 관계를 확인하기 위해 plot_parallel_coordinates(study) 이라는 명령어를 사용하여 아래와 같은 결과를 얻을 수 있다. (이 예시에서는 lr과 momentum이 파라미터)\n",
    "# 다른 방법으로 contour plot을 이용할 수도 있다. 이 결과는 plot_contour(study) 를 통해 얻을 수 있다.\n",
    "# 또한 slice_plot(study) 을 호출하여 slice plot을 만들 수 있다. 이는 각 파라미터에 대해 개별적인 최적의 부분 공간이 어디에 위치하는지 이해하는 데 도움이 될 수 있다.\n",
    "# 마지막으로 study history를 시각화 하기 위해 plot_optimization_history(study) 을 이용할 수도 있다.\n",
    "\n",
    "# 실제 학습에 사용되는 함수를 수정한다. (예시에서 train_mnist 함수가 이에 해당한다. ) 이 함수는 아래의 조건을 충족해야 한다.\n",
    "# 1. 평가 지표가 될 점수를 return 해야 한다. 이 함수 안에서 모델의 파라미터를 정해준다. (trial.suggest_.. 함수 이용). 이 함수는 trial을 매개변수로 받아야 한다.\n",
    "# 2. study.optimize 를 실행한다. 1에서 정의한 함수를 파라미터로 넘겨준다. 예시: study.optimize(train_mnist, n_trials=20, direction='maximize')\n",
    "df.head(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BangEnv",
   "language": "python",
   "name": "bangenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
